{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audiobooks business case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Preprocess the data. Balance the dataset. Create 3 datasets: training, validation, and test. Save the newly created sets in a tensor friendly format (e.g. *.npz)\n",
    "\n",
    "Since we are dealing with real life data, we will need to preprocess it a bit. This is the relevant code, which is not that hard, but is crucial to creating a good model.\n",
    "\n",
    "If you want to know how to do that, go through the code. In any case, this should do the trick for most datasets organized in the way: many inputs, and then 1 cell containing the targets (supervised learning datasets). Keep in mind that a specific problem may require additional preprocessing.\n",
    "\n",
    "Note that we have removed the header row, which contains the names of the categories. We simply want the data.\n",
    "\n",
    "This code does not include comments - it is the same as the one in the lesson. Please refer to the other file if you want the code with comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14084, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_csv_data = np.loadtxt('Audiobooks_data.csv', delimiter = ',')\n",
    "raw_csv_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14084, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscaled_inputs_all = raw_csv_data[:,1:-1]\n",
    "unscaled_inputs_all.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14084,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_all = raw_csv_data[:,-1]\n",
    "targets_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14084"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_all.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle the data\n",
    "\n",
    "Shuffle the data before balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14084, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscaled_inputs_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.arange(unscaled_inputs_all.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "# Use the shuffled indices to shuffle the inputs and targets.\n",
    "unscaled_inputs_all = unscaled_inputs_all[shuffled_indices]\n",
    "targets_all = targets_all[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14084, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscaled_inputs_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2237"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_one_targets = int(np.sum(targets_all))\n",
    "num_one_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14084,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_targets_counter = 0 \n",
    "indices_to_remove = []\n",
    "for i in range(targets_all.shape[0]):\n",
    "    if targets_all[i] == 0:\n",
    "        zero_targets_counter += 1\n",
    "        if zero_targets_counter > num_one_targets:\n",
    "            indices_to_remove.append(i)\n",
    "#indices_to_remove\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two new variables, one that will contain the inputs, and one that will contain the targets.\n",
    "# We delete all indices that we marked \"to remove\" in the loop above.\n",
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4474, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscaled_inputs_equal_priors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4474"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis=0)\n",
    "targets_equal_priors.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2160.  , 2160.  ,    5.54, ...,  680.4 ,    0.  ,  222.  ],\n",
       "       [1620.  , 1620.  ,    5.69, ...,    0.  ,    0.  ,   11.  ],\n",
       "       [2160.  , 2160.  ,    6.58, ...,    0.  ,    0.  ,  257.  ],\n",
       "       ...,\n",
       "       [1656.  , 4968.  ,    5.33, ...,    0.  ,    0.  ,  284.  ],\n",
       "       [1620.  , 1620.  ,    5.33, ...,  567.  ,    0.  ,    5.  ],\n",
       "       [2160.  , 2160.  ,    6.39, ...,    0.  ,    0.  ,   29.  ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscaled_inputs_equal_priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.21733222,  0.38110245, -0.30843237, ...,  2.0904448 ,\n",
       "        -0.18915319,  1.619826  ],\n",
       "       [ 0.1387235 , -0.23404019, -0.27973802, ..., -0.45101755,\n",
       "        -0.18915319, -0.64569851],\n",
       "       [ 1.21733222,  0.38110245, -0.1094849 , ..., -0.45101755,\n",
       "        -0.18915319,  1.9956239 ],\n",
       "       ...,\n",
       "       [ 0.21063074,  3.57984418, -0.34860445, ..., -0.45101755,\n",
       "        -0.18915319,  2.28552514],\n",
       "       [ 0.1387235 , -0.23404019, -0.34860445, ...,  1.66686774,\n",
       "        -0.18915319, -0.710121  ],\n",
       "       [ 1.21733222,  0.38110245, -0.14583107, ..., -0.45101755,\n",
       "        -0.18915319, -0.45243101]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4474"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_count = shuffled_inputs.shape[0]\n",
    "samples_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3579 447 448 4474\n"
     ]
    }
   ],
   "source": [
    "train_samples_count = int(0.8 * samples_count)\n",
    "validation_samples_count = int(0.1 * samples_count)\n",
    "test_samples_count = samples_count - train_samples_count - validation_samples_count\n",
    "\n",
    "print(train_samples_count, validation_samples_count, test_samples_count, samples_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\n",
    "validation_targets = shuffled_targets[train_samples_count:train_samples_count+validation_samples_count]\n",
    "\n",
    "test_inputs = shuffled_inputs[train_samples_count+validation_samples_count:]\n",
    "test_targets = shuffled_targets[train_samples_count+validation_samples_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1768.0 3579 0.49399273540095\n",
      "242.0 447 0.5413870246085011\n",
      "227.0 448 0.5066964285714286\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(train_targets), train_samples_count, np.sum(train_targets) / train_samples_count)\n",
    "print(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets) / validation_samples_count)\n",
    "print(np.sum(test_targets), test_samples_count, np.sum(test_targets) / test_samples_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the data in .npz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Audiobooks_data_train', inputs=train_inputs, targets=train_targets)\n",
    "np.savez('Audiobooks_data_validation', inputs=validation_inputs, targets=validation_targets)\n",
    "np.savez('Audiobooks_data_test', inputs=test_inputs, targets=test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING ALGORITHMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('Audiobooks_data_train.npz')\n",
    "train_inputs = npz['inputs'].astype(np.float)\n",
    "train_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "\n",
    "npz = np.load('Audiobooks_data_validation.npz')\n",
    "validation_inputs = npz['inputs'].astype(np.float)\n",
    "validation_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Audiobooks_data_test.npz')\n",
    "test_inputs = npz['inputs'].astype(np.float)\n",
    "test_targets = npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_layer_size = 50\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    \n",
    "    # tf.keras.layers.Dense is basically implementing: output = activation(dot(input, weight) + bias)\n",
    "    # it takes several arguments, but the most important ones for us are the hidden_layer_size and the activation function\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 3rd hidden layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 4th hidden layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 5th hidden layer\n",
    "    \n",
    "    \n",
    "    # the final layer is no different, we just make sure to activate it with softmax\n",
    "    tf.keras.layers.Dense(output_size, activation= 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3579 samples, validate on 447 samples\n",
      "Epoch 1/100\n",
      "3579/3579 - 1s - loss: 0.6525 - accuracy: 0.6351 - val_loss: 0.5556 - val_accuracy: 0.7360\n",
      "Epoch 2/100\n",
      "3579/3579 - 0s - loss: 0.4591 - accuracy: 0.7678 - val_loss: 0.4426 - val_accuracy: 0.7427\n",
      "Epoch 3/100\n",
      "3579/3579 - 0s - loss: 0.4056 - accuracy: 0.7784 - val_loss: 0.4216 - val_accuracy: 0.7651\n",
      "Epoch 4/100\n",
      "3579/3579 - 0s - loss: 0.3853 - accuracy: 0.7935 - val_loss: 0.4700 - val_accuracy: 0.7405\n",
      "Epoch 5/100\n",
      "3579/3579 - 0s - loss: 0.3774 - accuracy: 0.7988 - val_loss: 0.4328 - val_accuracy: 0.7450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x130fad710>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 100\n",
    "batch_size = 100\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "\n",
    "# note that this time the train, validation and test data are not iterable\n",
    "model.fit(train_inputs, # train inputs\n",
    "          train_targets, # train targets\n",
    "          batch_size=batch_size, # batch size\n",
    "          epochs=NUM_EPOCHS, # epochs that we will train for (assuming early stopping doesn't kick in)\n",
    "          # callbacks are functions called by a task when a task is completed\n",
    "          # task here is to check if val_loss is increasing\n",
    "          callbacks=[early_stopping], # early stopping\n",
    "          validation_data=(validation_inputs, validation_targets), # validation data\n",
    "        #validation_steps=10,\n",
    "          verbose = 2 # making sure we get enough information about the training process\n",
    "          )  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "448/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 576us/sample - loss: 0.3756 - accuracy: 0.8147\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.35. Test accuracy: 81.47%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.460979  0.5390209] 1\n",
      "[0.49729523 0.50270474] 1\n",
      "[0.99863225 0.00136767] 0\n",
      "[0.60345536 0.3965446 ] 1\n",
      "[9.999988e-01 1.178492e-06] 0\n",
      "[0.5533525  0.44664752] 0\n",
      "[0.30026925 0.6997308 ] 0\n",
      "[9.992901e-01 7.098777e-04] 0\n",
      "[0.00106896 0.998931  ] 1\n",
      "[9.9999404e-01 5.9963077e-06] 0\n",
      "[0.5361681 0.4638319] 1\n",
      "[0.00770489 0.99229515] 1\n",
      "[1.0000000e+00 1.0339983e-09] 0\n",
      "[0.56504256 0.43495747] 0\n",
      "[0.9978053 0.0021947] 0\n",
      "[0.24591367 0.7540863 ] 1\n",
      "[0.25366023 0.74633974] 1\n",
      "[0.51285034 0.48714963] 0\n",
      "[0.78317934 0.21682064] 0\n",
      "[0.59253895 0.4074611 ] 1\n",
      "[9.9984229e-01 1.5774026e-04] 0\n",
      "[0.28123963 0.7187604 ] 1\n",
      "[0.3339983 0.6660018] 0\n",
      "[9.9996555e-01 3.4422726e-05] 0\n",
      "[0.96837425 0.03162568] 0\n",
      "[0.43178368 0.5682163 ] 0\n",
      "[1.1108751e-05 9.9998891e-01] 1\n",
      "[0.5799369  0.42006305] 0\n",
      "[0.48199505 0.51800495] 0\n",
      "[0.51799643 0.48200363] 0\n",
      "[0.99612635 0.00387369] 0\n",
      "[0.5726402  0.42735988] 0\n",
      "[2.3316195e-05 9.9997663e-01] 1\n",
      "[0.2808846  0.71911544] 1\n",
      "[0.36898017 0.63101983] 0\n",
      "[0.6617531 0.3382469] 0\n",
      "[0.00100311 0.9989969 ] 1\n",
      "[0.00183458 0.9981654 ] 1\n",
      "[0.5231331  0.47686687] 0\n",
      "[0.9537692  0.04623077] 0\n",
      "[0.5288639  0.47113606] 0\n",
      "[6.2467666e-06 9.9999380e-01] 1\n",
      "[0.04386838 0.9561316 ] 1\n",
      "[0.6042866 0.3957133] 0\n",
      "[0.01952459 0.98047537] 1\n",
      "[1.1853791e-04 9.9988151e-01] 1\n",
      "[0.94710964 0.05289033] 0\n",
      "[0.2378294 0.7621706] 1\n",
      "[0.63700074 0.36299926] 1\n",
      "[0.8494382  0.15056181] 0\n",
      "[0.5799164  0.42008364] 0\n",
      "[1.0000000e+00 7.8097645e-10] 0\n",
      "[0.00117554 0.9988244 ] 1\n",
      "[0.18964098 0.810359  ] 1\n",
      "[0.26894405 0.7310559 ] 1\n",
      "[0.29539034 0.7046097 ] 1\n",
      "[0.98951226 0.01048777] 0\n",
      "[0.567208   0.43279204] 0\n",
      "[0.18235141 0.81764853] 1\n",
      "[0.94251186 0.05748817] 0\n",
      "[0.984519   0.01548104] 0\n",
      "[0.6386769  0.36132315] 0\n",
      "[0.5971303  0.40286976] 0\n",
      "[1.0000000e+00 1.0297898e-10] 0\n",
      "[0.5571112  0.44288877] 1\n",
      "[0.05143631 0.9485637 ] 1\n",
      "[0.54879904 0.45120105] 0\n",
      "[9.990871e-01 9.129081e-04] 0\n",
      "[0.06587453 0.9341254 ] 1\n",
      "[9.9991536e-01 8.4625237e-05] 0\n",
      "[0.56055254 0.4394474 ] 0\n",
      "[0.30387032 0.6961297 ] 1\n",
      "[7.5458673e-05 9.9992454e-01] 1\n",
      "[1.00000000e+00 1.08093005e-11] 0\n",
      "[0.65637654 0.3436234 ] 0\n",
      "[0.56504256 0.43495747] 1\n",
      "[0.46197826 0.53802174] 1\n",
      "[9.9998832e-01 1.1632143e-05] 0\n",
      "[8.1164006e-04 9.9918836e-01] 1\n",
      "[0.10871815 0.8912818 ] 1\n",
      "[0.6042866 0.3957133] 1\n",
      "[1.0000000e+00 6.7276495e-10] 0\n",
      "[0.58743036 0.41256964] 1\n",
      "[0.56260645 0.43739355] 0\n",
      "[0.63687015 0.36312985] 0\n",
      "[1.50708e-10 1.00000e+00] 1\n",
      "[0.6042866 0.3957133] 0\n",
      "[0.0038273 0.9961727] 1\n",
      "[0.60912293 0.39087716] 0\n",
      "[0.5447313  0.45526868] 1\n",
      "[0.56504256 0.43495747] 0\n",
      "[0.516381   0.48361894] 0\n",
      "[0.80994236 0.19005767] 0\n",
      "[0.26570278 0.73429716] 0\n",
      "[9.9982882e-01 1.7119275e-04] 0\n",
      "[6.375472e-04 9.993624e-01] 1\n",
      "[9.9999833e-01 1.6407798e-06] 0\n",
      "[0.4178334 0.5821666] 1\n",
      "[0.5338802  0.46611983] 0\n",
      "[9.9999964e-01 3.2489913e-07] 0\n",
      "[0.5528256 0.4471744] 0\n",
      "[0.6042866 0.3957133] 0\n",
      "[0.5528256 0.4471744] 0\n",
      "[0.90520597 0.09479407] 0\n",
      "[5.7574745e-09 1.0000000e+00] 1\n",
      "[0.56504256 0.43495747] 0\n",
      "[1.0000000e+00 4.2141604e-14] 0\n",
      "[0.30065954 0.69934046] 1\n",
      "[0.2718743 0.7281257] 1\n",
      "[0.29979202 0.700208  ] 0\n",
      "[0.43925497 0.56074506] 1\n",
      "[0.05787934 0.94212073] 1\n",
      "[0.00469879 0.99530125] 1\n",
      "[0.5354659 0.4645341] 0\n",
      "[0.00138566 0.9986143 ] 1\n",
      "[9.9930084e-01 6.9909258e-04] 0\n",
      "[0.56523573 0.43476433] 0\n",
      "[0.01741241 0.98258764] 1\n",
      "[0.9028021  0.09719793] 0\n",
      "[0.36102694 0.63897306] 0\n",
      "[0.58403534 0.41596472] 0\n",
      "[0.7226687  0.27733138] 0\n",
      "[0.5427196 0.4572804] 1\n",
      "[0.36102694 0.63897306] 0\n",
      "[0.99789053 0.00210945] 0\n",
      "[0.00653044 0.9934696 ] 1\n",
      "[0.5290413 0.4709587] 0\n",
      "[0.98864704 0.01135294] 0\n",
      "[0.2802691 0.7197309] 1\n",
      "[0.5539925  0.44600752] 1\n",
      "[0.24340604 0.756594  ] 0\n",
      "[0.00141387 0.9985862 ] 1\n",
      "[0.50336725 0.49663273] 0\n",
      "[0.557188   0.44281206] 1\n",
      "[0.00144884 0.9985512 ] 1\n",
      "[0.00413616 0.9958638 ] 1\n",
      "[0.50034124 0.49965876] 1\n",
      "[2.0785813e-04 9.9979216e-01] 1\n",
      "[9.9996126e-01 3.8798429e-05] 0\n",
      "[6.2209857e-04 9.9937785e-01] 1\n",
      "[0.03208778 0.96791226] 1\n",
      "[0.99463767 0.00536232] 0\n",
      "[0.5231331  0.47686687] 1\n",
      "[0.58713704 0.41286296] 0\n",
      "[9.9998057e-01 1.9463085e-05] 0\n",
      "[1.000000e+00 4.989709e-12] 0\n",
      "[0.906629   0.09337097] 0\n",
      "[0.00456031 0.9954397 ] 1\n",
      "[0.20537043 0.7946296 ] 1\n",
      "[5.0981547e-04 9.9949014e-01] 1\n",
      "[0.40626216 0.5937378 ] 1\n",
      "[0.01776881 0.9822312 ] 1\n",
      "[0.00468777 0.9953122 ] 1\n",
      "[0.2274253  0.77257466] 1\n",
      "[1.000000e+00 7.083429e-11] 0\n",
      "[0.52939945 0.47060055] 1\n",
      "[0.5494091 0.4505909] 0\n",
      "[9.9999988e-01 1.2304787e-07] 0\n",
      "[0.57771516 0.4222848 ] 1\n",
      "[9.9999905e-01 9.9838178e-07] 0\n",
      "[0.18837777 0.81162226] 1\n",
      "[4.8583915e-04 9.9951422e-01] 1\n",
      "[0.01201874 0.98798126] 1\n",
      "[0.03322061 0.9667795 ] 1\n",
      "[0.04139632 0.95860374] 1\n",
      "[3.9187327e-04 9.9960810e-01] 1\n",
      "[0.00225139 0.99774855] 1\n",
      "[0.63700074 0.36299926] 1\n",
      "[0.5231331  0.47686687] 1\n",
      "[9.9941027e-01 5.8973103e-04] 0\n",
      "[0.99271727 0.00728276] 0\n",
      "[0.5231331  0.47686687] 0\n",
      "[0.36897057 0.63102937] 1\n",
      "[0.5545502 0.4454498] 0\n",
      "[0.00144373 0.9985563 ] 1\n",
      "[1.5872620e-06 9.9999845e-01] 1\n",
      "[0.5231331  0.47686687] 0\n",
      "[1.0000000e+00 4.6452358e-09] 0\n",
      "[0.074995 0.925005] 1\n",
      "[0.30975878 0.6902412 ] 1\n",
      "[1.9079357e-07 9.9999976e-01] 1\n",
      "[0.58191204 0.418088  ] 1\n",
      "[4.895791e-04 9.995104e-01] 1\n",
      "[0.03981762 0.9601823 ] 1\n",
      "[0.47906885 0.5209311 ] 0\n",
      "[0.5649284  0.43507168] 1\n",
      "[0.48199505 0.51800495] 1\n",
      "[0.9740441  0.02595592] 0\n",
      "[0.18386212 0.8161379 ] 0\n",
      "[0.5231331  0.47686687] 0\n",
      "[0.9976012  0.00239883] 0\n",
      "[1.0000000e+00 1.2436162e-11] 0\n",
      "[7.9196871e-06 9.9999213e-01] 1\n",
      "[0.9955585  0.00444145] 0\n",
      "[0.48221925 0.5177807 ] 0\n",
      "[0.3444632 0.6555368] 0\n",
      "[0.39407736 0.60592264] 1\n",
      "[0.54143643 0.45856354] 0\n",
      "[0.6233278  0.37667227] 0\n",
      "[1.11795525e-04 9.99888182e-01] 1\n",
      "[0.9768435  0.02315655] 0\n",
      "[0.5012467  0.49875334] 0\n",
      "[0.5303787  0.46962133] 0\n",
      "[0.00123655 0.99876344] 1\n",
      "[0.20754865 0.7924514 ] 1\n",
      "[1.000000e+00 4.413045e-09] 0\n",
      "[0.02403612 0.9759639 ] 1\n",
      "[1.7736573e-04 9.9982268e-01] 1\n",
      "[0.60567874 0.39432123] 1\n",
      "[0.7831132  0.21688683] 0\n",
      "[0.56320393 0.43679607] 1\n",
      "[0.42394626 0.5760537 ] 1\n",
      "[1.000000e+00 1.440575e-10] 0\n",
      "[4.9308938e-04 9.9950695e-01] 1\n",
      "[0.2540349 0.7459651] 1\n",
      "[0.48199505 0.51800495] 1\n",
      "[0.52829623 0.47170374] 1\n",
      "[0.46851265 0.5314874 ] 1\n",
      "[0.7115304  0.28846964] 0\n",
      "[5.8806484e-04 9.9941194e-01] 1\n",
      "[0.00216029 0.9978397 ] 1\n",
      "[9.9998069e-01 1.9361414e-05] 0\n",
      "[0.593557   0.40644297] 0\n",
      "[0.19904457 0.8009554 ] 1\n",
      "[2.7598284e-05 9.9997234e-01] 1\n",
      "[0.00389223 0.99610776] 1\n",
      "[0.5231331  0.47686687] 1\n",
      "[0.9876155  0.01238439] 0\n",
      "[0.58191204 0.418088  ] 0\n",
      "[0.19230312 0.8076969 ] 0\n",
      "[0.6153054  0.38469455] 0\n",
      "[0.44227836 0.5577217 ] 1\n",
      "[1.0000000e+00 1.0760753e-11] 0\n",
      "[0.00503782 0.9949622 ] 1\n",
      "[0.5917824  0.40821764] 1\n",
      "[0.58191204 0.418088  ] 1\n",
      "[0.3395327  0.66046727] 1\n",
      "[1.3978094e-05 9.9998605e-01] 1\n",
      "[0.21796861 0.78203136] 0\n",
      "[0.71795464 0.28204533] 0\n",
      "[0.9914808 0.0085192] 0\n",
      "[0.44389033 0.5561097 ] 0\n",
      "[0.49046558 0.50953436] 1\n",
      "[0.6425705 0.3574295] 1\n",
      "[0.5231331  0.47686687] 0\n",
      "[0.9965184  0.00348157] 0\n",
      "[0.4504924  0.54950756] 1\n",
      "[0.2578583 0.7421417] 1\n",
      "[1.0000000e+00 3.1500944e-11] 0\n",
      "[0.54942286 0.4505771 ] 1\n",
      "[9.9999988e-01 1.6314539e-07] 0\n",
      "[0.00143218 0.9985678 ] 1\n",
      "[0.4832313 0.5167687] 0\n",
      "[0.5295548  0.47044522] 0\n",
      "[0.15667486 0.84332514] 1\n",
      "[0.46519 0.53481] 0\n",
      "[9.9997604e-01 2.3915387e-05] 0\n",
      "[0.68021655 0.31978342] 0\n",
      "[0.56352276 0.43647715] 0\n",
      "[9.9999356e-01 6.4042647e-06] 0\n",
      "[0.00168338 0.99831665] 1\n",
      "[1.4354155e-05 9.9998569e-01] 1\n",
      "[0.00496736 0.99503267] 1\n",
      "[1.00000000e+00 1.07119605e-10] 0\n",
      "[0.00857989 0.99142015] 1\n",
      "[4.568711e-04 9.995432e-01] 1\n",
      "[0.00678108 0.99321896] 1\n",
      "[9.9954802e-01 4.5192044e-04] 0\n",
      "[0.00232406 0.99767596] 1\n",
      "[0.83391535 0.16608465] 0\n",
      "[0.5962443  0.40375578] 0\n",
      "[4.7125726e-04 9.9952877e-01] 1\n",
      "[1.1805534e-04 9.9988198e-01] 1\n",
      "[1.0000000e+00 1.2077234e-09] 0\n",
      "[0.5473174  0.45268258] 1\n",
      "[0.6042866 0.3957133] 0\n",
      "[0.42356512 0.5764349 ] 1\n",
      "[0.821437 0.178563] 1\n",
      "[0.56504256 0.43495747] 0\n",
      "[0.8482566  0.15174338] 0\n",
      "[0.633867 0.366133] 1\n",
      "[0.32715827 0.67284167] 1\n",
      "[0.32658264 0.6734174 ] 1\n",
      "[0.00175247 0.9982475 ] 1\n",
      "[0.9828272  0.01717276] 0\n",
      "[0.21278024 0.7872198 ] 0\n",
      "[0.36038765 0.6396123 ] 0\n",
      "[9.9905545e-01 9.4460609e-04] 0\n",
      "[9.9996281e-01 3.7169615e-05] 0\n",
      "[0.44939896 0.550601  ] 1\n",
      "[0.5101694  0.48983055] 1\n",
      "[0.9105119 0.0894881] 0\n",
      "[1.0000000e+00 6.0687875e-13] 0\n",
      "[0.00117979 0.9988201 ] 1\n",
      "[0.36377308 0.6362269 ] 0\n",
      "[0.6144456 0.3855544] 0\n",
      "[9.9997759e-01 2.2425022e-05] 0\n",
      "[0.77721405 0.22278598] 0\n",
      "[1.000000e+00 9.145935e-09] 0\n",
      "[0.00863056 0.9913694 ] 1\n",
      "[6.5724668e-04 9.9934274e-01] 1\n",
      "[0.81726795 0.18273203] 0\n",
      "[0.4631158 0.5368842] 0\n",
      "[0.5955709  0.40442908] 0\n",
      "[9.9999988e-01 1.6217524e-07] 0\n",
      "[0.5458825  0.45411757] 1\n",
      "[0.01402336 0.9859766 ] 1\n",
      "[0.48221925 0.5177807 ] 1\n",
      "[0.90390384 0.09609619] 0\n",
      "[9.9999499e-01 5.0171457e-06] 0\n",
      "[0.6925171  0.30748284] 0\n",
      "[0.00155511 0.99844486] 1\n",
      "[0.4799259 0.520074 ] 1\n",
      "[0.5579877 0.4420124] 0\n",
      "[0.01147347 0.98852646] 1\n",
      "[0.56504256 0.43495747] 0\n",
      "[0.27797264 0.7220273 ] 1\n",
      "[0.58161324 0.4183867 ] 1\n",
      "[0.00480257 0.9951975 ] 1\n",
      "[0.00481351 0.9951865 ] 1\n",
      "[0.49423328 0.50576675] 0\n",
      "[0.4801277  0.51987225] 0\n",
      "[0.77960956 0.22039047] 0\n",
      "[1.0000000e+00 1.7624911e-12] 0\n",
      "[0.5607136  0.43928644] 0\n",
      "[0.38089585 0.61910415] 1\n",
      "[6.290544e-04 9.993710e-01] 1\n",
      "[0.5231331  0.47686687] 0\n",
      "[0.67670393 0.32329604] 1\n",
      "[0.26175803 0.738242  ] 1\n",
      "[0.52949303 0.47050697] 0\n",
      "[0.5917435 0.4082565] 1\n",
      "[0.6220043  0.37799573] 1\n",
      "[0.9901037  0.00989634] 0\n",
      "[0.5231331  0.47686687] 0\n",
      "[0.5474171 0.4525829] 0\n",
      "[0.9795099  0.02049012] 0\n",
      "[0.23594427 0.76405567] 1\n",
      "[0.32816324 0.67183673] 1\n",
      "[0.21871093 0.7812891 ] 0\n",
      "[8.952053e-04 9.991048e-01] 1\n",
      "[6.1170140e-04 9.9938834e-01] 1\n",
      "[0.2650827  0.73491734] 1\n",
      "[0.5231331  0.47686687] 0\n",
      "[9.999924e-01 7.660201e-06] 0\n",
      "[2.889261e-04 9.997111e-01] 1\n",
      "[0.56504256 0.43495747] 0\n",
      "[9.9916863e-01 8.3134195e-04] 0\n",
      "[0.9962836  0.00371638] 0\n",
      "[0.5689338  0.43106616] 1\n",
      "[0.67670393 0.32329604] 0\n",
      "[0.01333608 0.98666394] 1\n",
      "[0.49720007 0.5027999 ] 0\n",
      "[9.9996185e-01 3.8200978e-05] 0\n",
      "[0.703732   0.29626802] 1\n",
      "[0.66905236 0.33094767] 0\n",
      "[0.00206752 0.99793243] 1\n",
      "[9.9998009e-01 1.9857554e-05] 0\n",
      "[0.57719266 0.42280737] 1\n",
      "[0.17759007 0.82241   ] 1\n",
      "[0.00154372 0.99845624] 1\n",
      "[0.99841046 0.00158949] 0\n",
      "[0.02711003 0.97289   ] 1\n",
      "[0.46478868 0.5352113 ] 1\n",
      "[0.6570038  0.34299618] 0\n",
      "[1.4416931e-05 9.9998558e-01] 1\n",
      "[0.47338003 0.52662003] 0\n",
      "[9.999949e-01 5.076431e-06] 0\n",
      "[2.1863445e-04 9.9978143e-01] 1\n",
      "[0.4760553  0.52394474] 1\n",
      "[0.6822894  0.31771052] 0\n",
      "[0.27722153 0.72277844] 1\n",
      "[0.9987349  0.00126513] 0\n",
      "[0.9932766  0.00672349] 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0025812e-04 9.9979979e-01] 1\n",
      "[0.00413616 0.9958638 ] 1\n",
      "[0.38089585 0.61910415] 1\n",
      "[0.0176383  0.98236173] 1\n",
      "[0.67670393 0.32329604] 1\n",
      "[0.01906239 0.98093766] 1\n",
      "[0.6409063 0.3590938] 0\n",
      "[0.55460477 0.44539523] 1\n",
      "[0.56504256 0.43495747] 0\n",
      "[0.00255662 0.99744344] 1\n",
      "[0.46125382 0.5387462 ] 1\n",
      "[0.47334802 0.5266519 ] 1\n",
      "[0.00119071 0.99880934] 1\n",
      "[0.5586287 0.4413714] 0\n",
      "[0.01816665 0.9818333 ] 1\n",
      "[0.56504256 0.43495747] 0\n",
      "[0.98991245 0.01008763] 0\n",
      "[0.32500154 0.6749985 ] 0\n",
      "[0.00101681 0.9989832 ] 1\n",
      "[0.50336725 0.49663273] 0\n",
      "[0.9982849  0.00171508] 0\n",
      "[0.3644401  0.63555986] 0\n",
      "[0.04362514 0.9563749 ] 1\n",
      "[0.46870708 0.531293  ] 0\n",
      "[2.3033557e-04 9.9976963e-01] 1\n",
      "[0.06199101 0.938009  ] 1\n",
      "[0.48697305 0.51302695] 1\n",
      "[0.0842142 0.9157858] 1\n",
      "[0.95494986 0.04505016] 0\n",
      "[0.9987778  0.00122216] 0\n",
      "[0.6025654  0.39743462] 1\n",
      "[0.56504256 0.43495747] 0\n",
      "[0.5981697 0.4018303] 0\n",
      "[0.53056836 0.4694317 ] 1\n",
      "[1.000000e+00 8.932945e-09] 0\n",
      "[9.9999201e-01 7.9842675e-06] 0\n",
      "[6.8165816e-04 9.9931836e-01] 1\n",
      "[0.01316018 0.9868398 ] 1\n",
      "[0.52543366 0.47456637] 1\n",
      "[0.50558364 0.4944164 ] 0\n",
      "[0.5217967 0.4782033] 1\n",
      "[9.9987388e-01 1.2608973e-04] 0\n",
      "[1.0752649e-05 9.9998927e-01] 1\n",
      "[0.36102694 0.63897306] 1\n",
      "[0.22497943 0.7750206 ] 0\n",
      "[0.24446362 0.7555363 ] 1\n",
      "[0.9957274  0.00427255] 0\n",
      "[0.47287357 0.52712643] 1\n",
      "[1.3939443e-06 9.9999857e-01] 1\n",
      "[0.34683722 0.65316284] 0\n",
      "[0.2052516  0.79474837] 1\n",
      "[0.00964555 0.9903544 ] 1\n",
      "[0.5231331  0.47686687] 1\n",
      "[0.64583635 0.35416365] 1\n",
      "[0.15353774 0.8464623 ] 1\n",
      "[0.17880838 0.8211916 ] 1\n",
      "[1.0000000e+00 1.4127306e-10] 0\n",
      "[0.10871815 0.8912818 ] 1\n",
      "[0.6505468  0.34945327] 0\n",
      "[0.25374   0.7462599] 0\n",
      "[0.38755906 0.612441  ] 1\n",
      "[0.48162282 0.5183771 ] 1\n",
      "[0.78554374 0.2144562 ] 0\n",
      "[0.9987436  0.00125645] 0\n",
      "[1.0000000e+00 6.1374563e-09] 0\n",
      "[0.6383066  0.36169332] 1\n",
      "[0.45685458 0.5431455 ] 1\n",
      "[0.30415887 0.69584113] 1\n",
      "[0.8270509  0.17294906] 0\n",
      "[0.16831084 0.8316891 ] 1\n",
      "[0.0410856 0.9589144] 1\n",
      "[1.1266677e-04 9.9988735e-01] 1\n",
      "[0.9461747  0.05382529] 0\n",
      "[0.46908087 0.5309192 ] 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(prediction)):\n",
    "    print(prediction[i], test_targets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "1 1\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "1 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 1\n",
      "1 0\n",
      "1 1\n",
      "0 0\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "0 1\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "0 0\n",
      "0 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "1 1\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "1 1\n",
      "1 0\n",
      "0 0\n",
      "1 1\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "1 1\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 1\n",
      "1 1\n",
      "0 0\n",
      "0 1\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "1 1\n",
      "1 0\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "0 0\n",
      "0 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(prediction)):\n",
    "    print(np.argmax(prediction[i]), test_targets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
