{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = keras.datasets.fashion_mnist\n",
    "\n",
    "mnist_dataset, mnist_info = tfds.load(name='fashion_mnist', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': <PrefetchDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>,\n",
       " 'train': <PrefetchDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(train_images, train_labels), (test_images, test_labels) = data.load_data()\n",
    "mnist_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='fashion_mnist',\n",
       "    version=3.0.1,\n",
       "    description='Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.',\n",
       "    homepage='https://github.com/zalandoresearch/fashion-mnist',\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
       "    }),\n",
       "    total_num_examples=70000,\n",
       "    splits={\n",
       "        'test': 10000,\n",
       "        'train': 60000,\n",
       "    },\n",
       "    supervised_keys=('image', 'label'),\n",
       "    citation=\"\"\"@article{DBLP:journals/corr/abs-1708-07747,\n",
       "      author    = {Han Xiao and\n",
       "                   Kashif Rasul and\n",
       "                   Roland Vollgraf},\n",
       "      title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n",
       "                   Algorithms},\n",
       "      journal   = {CoRR},\n",
       "      volume    = {abs/1708.07747},\n",
       "      year      = {2017},\n",
       "      url       = {http://arxiv.org/abs/1708.07747},\n",
       "      archivePrefix = {arXiv},\n",
       "      eprint    = {1708.07747},\n",
       "      timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n",
       "      biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n",
       "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       "    }\"\"\",\n",
       "    redistribution_info=,\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once we have loaded the dataset, we can easily extract the training and testing dataset with the built references\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=302, shape=(), dtype=int64, numpy=6000>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by default, TF has training and testing datasets, but no validation set, thus we must split it on our own\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "# let's cast this number to an integer, as a float may cause an error along the way\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "num_validation_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=304, shape=(), dtype=int64, numpy=10000>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "# once more, we'd prefer an integer (rather than the default float)\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)\n",
    "num_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scale(image, label):\n",
    "    \n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.\n",
    "\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((28, 28, 1), ()), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_and_validation_data = mnist_train.map(scale)\n",
    "scaled_train_and_validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((28, 28, 1), ()), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = mnist_test.map(scale)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: ((28, 28, 1), ()), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "shuffled_train_and_validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((28, 28, 1), ()), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
    "validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SkipDataset shapes: ((28, 28, 1), ()), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trian_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n",
    "trian_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trian_data = trian_data.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = validation_data.batch(num_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.batch(num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_inputs, validation_targets = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag',' ANkle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 128\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28,28, 1)),\n",
    "    keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
    "    keras.layers.Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\n",
    "    keras.layers.Dense(hidden_layer_size, activation='relu'), # 3rd hidden layer\n",
    "    keras.layers.Dense(output_size, activation= 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 11s - loss: 0.5452 - accuracy: 0.8076 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "540/540 - 6s - loss: 0.3806 - accuracy: 0.8622 - val_loss: 0.3523 - val_accuracy: 0.8735\n",
      "Epoch 3/5\n",
      "540/540 - 6s - loss: 0.3400 - accuracy: 0.8759 - val_loss: 0.3663 - val_accuracy: 0.8670\n",
      "Epoch 4/5\n",
      "540/540 - 6s - loss: 0.3185 - accuracy: 0.8833 - val_loss: 0.3093 - val_accuracy: 0.8853\n",
      "Epoch 5/5\n",
      "540/540 - 6s - loss: 0.2990 - accuracy: 0.8888 - val_loss: 0.2998 - val_accuracy: 0.8902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12fd12be0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the maximum number of epochs\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# we fit the model, specifying the\n",
    "# training data\n",
    "# the total number of epochs\n",
    "# and the validation data we just created ourselves in the format: (inputs,targets)\n",
    "model.fit(trian_data,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=(validation_inputs, validation_targets),\n",
    "    validation_steps=10,\n",
    "    verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 950ms/step - loss: 0.3451 - accuracy: 0.8736\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.35. Test accuracy: 87.36%\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.2368151e-06, 5.8968230e-06, 8.6147711e-06, 2.8596000e-06,\n",
       "       5.0324525e-06, 5.2452664e-04, 5.4924508e-06, 9.9877328e-01,\n",
       "       3.1615193e-05, 6.3445605e-04], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val = prediction[8]\n",
    "pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sneaker\n"
     ]
    }
   ],
   "source": [
    "print(class_name[np.argmax(pred_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'BatchDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-75840d63bf89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Actual:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'BatchDataset' object is not subscriptable"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    plt.grid(False)\n",
    "    plt.imshow(test_data[i], cmap = plt.cm.binary)\n",
    "    plt.xlabel=(\"Actual:\" + class_name[test_labels[i]])\n",
    "    plt.title=(\"Prediction:\" + class_name[np.argmax(pred_val)])\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Actual:\" + class_name[test_labels[i]])\n",
    "    print(\"Prediction:\" + class_name[np.argmax(prediction[i])])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, None, None, None, 28, 28, 1), (None, None, None, None)), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "val = []\n",
    "for i in test_data:\n",
    "    val = i\n",
    "    counter += 1 \n",
    "    if counter > 8:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[[[[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     ...\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]]\n",
      "\n",
      "\n",
      "    [[[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     ...\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]]\n",
      "\n",
      "\n",
      "    [[[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     ...\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]]\n",
      "\n",
      "\n",
      "    ...\n",
      "\n",
      "\n",
      "    [[[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     ...\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]]\n",
      "\n",
      "\n",
      "    [[[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     ...\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.29803923]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.02352941]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]]\n",
      "\n",
      "\n",
      "    [[[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     ...\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]\n",
      "\n",
      "     [[0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      ...\n",
      "      [0.        ]\n",
      "      [0.        ]\n",
      "      [0.        ]]]]]]], shape=(1, 1, 1, 10000, 28, 28, 1), dtype=float32)\n",
      "tf.Tensor([[[[4 4 9 ... 6 4 1]]]], shape=(1, 1, 1, 10000), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for i in val:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
